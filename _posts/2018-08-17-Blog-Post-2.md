---
layout: post
title: "Raylyn's Blog Post 1"
date: 2018-08-17
week: Week 2
---
This is a test of a long post. The first important step in writing a paper is taking some time to understand what the professor is looking for. If you know that, you can write to the rubric and pick up easy points along the way.

Universities mandate that professors given students rubrics or some form of assessment guideline. Remember, the rubric for the course on the assignment sheet you’ve been given, you will find a general rubric in the class syllabus, or the professor will include a rubric with an assignment sheet.

If the professor does not provide these things to you, don’t be afraid to ask for them. It’s completely unfair to assess a student if the student doesn’t know what’s expected of them. When you ask, be courteous.

The most common form of machine learning, deep or not, is super
-
vised learning. Imagine that we want to build a system that can classify 
images as containing, say, a house, a car, a person or a pet. We first 
collect a large data set of images of houses, cars, people and pets, each 
labelled with its category. During training, the machine is shown an 
image and produces an output in the form of a vector of scores, one 
for each category. We want the desired category to have the highest 
score of all categories, but this is unlikely to happen before training. 
We compute an objective function that measures the error (or dis
-
tance) between the output scores and the desired pattern of scores. The 
machine then modifies its internal adjustable parameters to reduce 
this error. These adjustable parameters, often called weights, are real 
numbers that can be seen as ‘knobs’ that define the input–output func
-
tion of the machine. In a typical deep-learning system, there may be 
hundreds of millions of these adjustable weights, and hundreds of 
millions of labelled examples with which to train the machine. 
To properly adjust the weight vector, the learning algorithm com
-
putes a gradient vector that, for each weight, indicates by what amount 
the error would increase or decrease if the weight were increased by a 
tiny amount. The weight vector is then adjusted in the opposite direc
-
tion to the gradient vector. 
The objective function, averaged over all the training examples, can 
